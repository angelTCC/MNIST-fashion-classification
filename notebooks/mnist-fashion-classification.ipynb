{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "347e7e15",
   "metadata": {},
   "source": [
    "## Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36994703",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 15:12:53.258032: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-04 15:12:53.341748: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-04 15:12:55.391033: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import os\n",
    "from pathlib import Path \n",
    "from time import strftime \n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c299b",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69df14f",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3ac973",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full,y_train_full), (X_test, y_test) = fashion_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6ae61e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"Tshirt\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72bf1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d477bc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255. \n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a931976",
   "metadata": {},
   "source": [
    "### Store img test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9e1dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../mnist-fashion-classification/public/images/'\n",
    "for num,class_name in enumerate(class_names):\n",
    "    index = [i for i,value in enumerate(y_test) if value==num]\n",
    "    for i,lab in enumerate(index[:50]):\n",
    "        os.makedirs( path + class_name, exist_ok=True)\n",
    "        img_array = (X_test[lab] * 255).astype(np.uint8)\n",
    "        Image.fromarray(img_array).save( path + class_name + '/' + str(i) + '.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c5eddb",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e37d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1950980",
   "metadata": {},
   "source": [
    "#### Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c1e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_pr = {\n",
    "    \"input_shape\": (28, 28, 1),\n",
    "    \"hidden_units\": [300, 200, 100],\n",
    "    \"activation\": \"relu\",\n",
    "    \"kernel_initializer\": \"he_normal\",\n",
    "    \"num_classes\": 10,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "077eb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(config: dict) -> tf.keras.Model:\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Input\n",
    "    model.add(tf.keras.Input(shape=config[\"input_shape\"]))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # Hidden layers (dynamic)\n",
    "    for units in config[\"hidden_units\"]:\n",
    "        model.add(\n",
    "            tf.keras.layers.Dense(\n",
    "                units,\n",
    "                activation=config[\"activation\"],\n",
    "                kernel_initializer=config[\"kernel_initializer\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Output layer\n",
    "    model.add(\n",
    "        tf.keras.layers.Dense(\n",
    "            config[\"num_classes\"],\n",
    "            activation=\"softmax\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer_name = config[\"optimizer\"].lower()\n",
    "    lr = config[\"lr\"]\n",
    "\n",
    "    if optimizer_name == \"adam\":\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=lr, momentum=0.9)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported optimizer: {optimizer_name}\")\n",
    "\n",
    "    # Compile\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "535ed2ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 15:24:51.672595: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = build_model(exp_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a397fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">60,200</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,100</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            â”‚       \u001b[38;5;34m235,500\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            â”‚        \u001b[38;5;34m60,200\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            â”‚        \u001b[38;5;34m20,100\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             â”‚         \u001b[38;5;34m1,010\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">316,810</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m316,810\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">316,810</span> (1.21 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m316,810\u001b[0m (1.21 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473f0773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-03 16:34:57.767463: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.Input(shape=(28, 28,1)))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(200, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88612406",
   "metadata": {},
   "source": [
    "#### Model with Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20b6e101",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_batch = tf.keras.Sequential()\n",
    "model_batch.add(tf.keras.Input(shape=(28, 28, 1)))\n",
    "model_batch.add(tf.keras.layers.Flatten())\n",
    "\n",
    "# Dense layer 1\n",
    "model_batch.add(tf.keras.layers.Dense(300, kernel_initializer='he_normal', use_bias=False))\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "# Dense layer 2\n",
    "model_batch.add(tf.keras.layers.Dense(200, kernel_initializer='he_normal', use_bias=False))\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "# Dense layer 3\n",
    "model_batch.add(tf.keras.layers.Dense(100, kernel_initializer='he_normal', use_bias=False))\n",
    "model_batch.add(tf.keras.layers.BatchNormalization())\n",
    "model_batch.add(tf.keras.layers.Activation('relu'))\n",
    "\n",
    "# Output layer\n",
    "model_batch.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model_batch.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6cf014",
   "metadata": {},
   "source": [
    "#### Model with batch and dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd15a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b_r = tf.keras.Sequential()\n",
    "model_b_r.add(tf.keras.layers.InputLayer(input_shape=(28, 28,1)))\n",
    "model_b_r.add(tf.keras.layers.Flatten())  # <-- Add this line!\n",
    "\n",
    "\n",
    "# Dense layer 1\n",
    "model_b_r.add(tf.keras.layers.Dense(300, kernel_initializer='he_normal', use_bias=False))\n",
    "model_b_r.add(tf.keras.layers.BatchNormalization())\n",
    "model_b_r.add(tf.keras.layers.Activation('relu'))\n",
    "model_b_r.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Dense layer 2\n",
    "model_b_r.add(tf.keras.layers.Dense(200, kernel_initializer='he_normal', use_bias=False))\n",
    "model_b_r.add(tf.keras.layers.BatchNormalization())\n",
    "model_b_r.add(tf.keras.layers.Activation('relu'))\n",
    "model_b_r.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Dense layer 3\n",
    "model_b_r.add(tf.keras.layers.Dense(100, kernel_initializer='he_normal', use_bias=False))\n",
    "model_b_r.add(tf.keras.layers.BatchNormalization())\n",
    "model_b_r.add(tf.keras.layers.Activation('relu'))\n",
    "model_b_r.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Output layer (no regularization here usually)\n",
    "model_b_r.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "model_b_r.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e371cfc",
   "metadata": {},
   "source": [
    "#### Model with batch, droutout and schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb48bda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b_r_s = tf.keras.Sequential()\n",
    "model_b_r_s.add(tf.keras.layers.InputLayer(input_shape=(28, 28,1)))\n",
    "model_b_r_s.add(tf.keras.layers.Flatten())  # <-- Add this line!\n",
    "\n",
    "\n",
    "# Dense layer 1\n",
    "model_b_r_s.add(tf.keras.layers.Dense(300, kernel_initializer='he_normal', use_bias=False))\n",
    "model_b_r_s.add(tf.keras.layers.BatchNormalization())\n",
    "model_b_r_s.add(tf.keras.layers.Activation('relu'))\n",
    "model_b_r_s.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Dense layer 2\n",
    "model_b_r_s.add(tf.keras.layers.Dense(200, kernel_initializer='he_normal', use_bias=False))\n",
    "model_b_r_s.add(tf.keras.layers.BatchNormalization())\n",
    "model_b_r_s.add(tf.keras.layers.Activation('relu'))\n",
    "model_b_r_s.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Dense layer 3\n",
    "model_b_r_s.add(tf.keras.layers.Dense(100, kernel_initializer='he_normal', use_bias=False))\n",
    "model_b_r_s.add(tf.keras.layers.BatchNormalization())\n",
    "model_b_r_s.add(tf.keras.layers.Activation('relu'))\n",
    "model_b_r_s.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# Output layer (no regularization here usually)\n",
    "model_b_r_s.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Optimizer\n",
    "initial_lr = 0.01\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=initial_lr,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model_b_r_s.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab311125",
   "metadata": {},
   "source": [
    "# Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e88e840",
   "metadata": {},
   "source": [
    "### Set up Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2c9cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir(root_logdir=\"my_logs\"):\n",
    "\treturn Path(root_logdir) / strftime(\"run_%Y_%m_%d_%H_%M_%S\") \n",
    "\n",
    "run_logdir = get_run_logdir()  # e.g., my_logs/run_2022_08_01_17_25_59 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84ea45b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir=run_logdir,\n",
    "    histogram_freq=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc21f4d",
   "metadata": {},
   "source": [
    "run the server tensorboard --logdir ./my_logs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b934ae67",
   "metadata": {},
   "source": [
    "## Set up MLFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50ab31b",
   "metadata": {},
   "source": [
    "First run the mlflow server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422c48a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/04 15:28:50 INFO mlflow.tracking.fluent: Experiment with name 'my-first-experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1767558530543, experiment_id='1', last_update_time=1767558530543, lifecycle_stage='active', name='my-first-experiment', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"my-first-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e38628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Tracking URI: http://localhost:5000\n",
      "Active Experiment: <Experiment: artifact_location='mlflow-artifacts:/1', creation_time=1767558530543, experiment_id='1', last_update_time=1767558530543, lifecycle_stage='active', name='my-first-experiment', tags={'mlflow.experimentKind': 'custom_model_development'}>\n",
      "âœ“ Successfully connected to MLflow!\n",
      "ğŸƒ View run salty-dolphin-916 at: http://localhost:5000/#/experiments/1/runs/46a45aeee9c54500952706c4c480bd7f\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "# Print connection information\n",
    "print(f\"MLflow Tracking URI: {mlflow.get_tracking_uri()}\")\n",
    "print(f\"Active Experiment: {mlflow.get_experiment_by_name('my-first-experiment')}\")\n",
    "\n",
    "# Test logging\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"test_param\", \"test_value\")\n",
    "    print(\"âœ“ Successfully connected to MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3bdd86",
   "metadata": {},
   "source": [
    "## Logging models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15a69be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"input_shape\": (28, 28, 1),\n",
    "    \"hidden_units\": [300, 200, 100],\n",
    "    \"activation\": \"relu\",\n",
    "    \"kernel_initializer\": \"he_normal\",\n",
    "    \"num_classes\": 10,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"lr\": 0.01\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35dbf643",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {\n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 64,\n",
    "    \"experiment_name\": \"model\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec8dbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c993de8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 15:57:41.613911: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 172480000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-04 15:58:44.028884: W external/local_xla/xla/tsl/framework/cpu_allocator_impl.cc:84] Allocation of 15680000 exceeds 10% of free system memory.\n",
      "2026/01/04 15:58:44 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2026/01/04 15:58:45 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c6293dd9e003426e8d45a20b61e0fbe8\n",
      "runs:/c6293dd9e003426e8d45a20b61e0fbe8/model\n",
      "ğŸƒ View run model at: http://localhost:5000/#/experiments/1/runs/c6293dd9e003426e8d45a20b61e0fbe8\n",
      "ğŸ§ª View experiment at: http://localhost:5000/#/experiments/1\n"
     ]
    }
   ],
   "source": [
    "runs_info = []\n",
    "\n",
    "experiments = {\n",
    "    \"name\": \"model\",\n",
    "    \"epochs\": 3,\n",
    "    \"batch_size\": 8\n",
    "}\n",
    "\n",
    "with mlflow.start_run(run_name=experiments[\"name\"]):\n",
    "\n",
    "    # ---- log training params ----\n",
    "    mlflow.log_param(\"epochs\", experiments[\"epochs\"])\n",
    "    mlflow.log_param(\"batch_size\", experiments[\"batch_size\"])\n",
    "\n",
    "    # ---- TRAIN (no history needed) ----\n",
    "    model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=experiments[\"epochs\"],\n",
    "        batch_size=experiments[\"batch_size\"],\n",
    "        validation_data=(X_valid, y_valid),\n",
    "        callbacks=[mlflow.tensorflow.MlflowCallback()],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    # ---- EVALUATION using compiled metrics ----\n",
    "    val_results = model.evaluate(X_valid, y_valid, verbose=False)\n",
    "    test_results = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "    # ---- map metric names to values ----\n",
    "    val_metrics = dict(zip(\n",
    "        [f\"val_{name}\" for name in model.metrics_names],\n",
    "        val_results\n",
    "    ))\n",
    "\n",
    "    test_metrics = dict(zip(\n",
    "        [f\"test_{name}\" for name in model.metrics_names],\n",
    "        test_results\n",
    "    ))\n",
    "\n",
    "    # ---- log ALL metrics dynamically ----\n",
    "    mlflow.log_metrics({\n",
    "        **val_metrics,\n",
    "        **test_metrics\n",
    "    })\n",
    "\n",
    "    # ---- log model artifact (NOT register) ----\n",
    "    mlflow.tensorflow.log_model(\n",
    "        model,\n",
    "        artifact_path=\"model\"\n",
    "    )\n",
    "\n",
    "    # ---- run info ----\n",
    "    run_id = mlflow.active_run().info.run_id\n",
    "    model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "    print(run_id)\n",
    "    print(model_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6372b1",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "28ed231e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model by alias (best practice)\n",
    "loaded_model = mlflow.tensorflow.load_model(\n",
    "    model_uri=\"models:/first_model_register@first_champion\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3a1c8b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = loaded_model.evaluate(X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dcb4c77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4404793083667755, 0.845300018787384]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ca7a5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = loaded_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8ffb1ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(8453)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test==np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfa53f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23e82d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8453"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(8453/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4729e1",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67d7f79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Train log tags:\n",
      "images: []\n",
      "audio: []\n",
      "histograms: []\n",
      "scalars: []\n",
      "distributions: []\n",
      "tensors: ['keras', 'epoch_loss', 'epoch_accuracy', 'epoch_learning_rate']\n",
      "graph: False\n",
      "meta_graph: False\n",
      "run_metadata: []\n",
      "\n",
      "ğŸ“¦ Validation log tags:\n",
      "images: []\n",
      "audio: []\n",
      "histograms: []\n",
      "scalars: []\n",
      "distributions: []\n",
      "tensors: ['evaluation_loss_vs_iterations', 'evaluation_accuracy_vs_iterations', 'epoch_loss', 'epoch_accuracy']\n",
      "graph: False\n",
      "meta_graph: False\n",
      "run_metadata: []\n",
      "\n",
      "âŒ No scalar tags found in both logs to plot.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "def load_event_tags(log_dir):\n",
    "    ea = EventAccumulator(log_dir)\n",
    "    ea.Reload()\n",
    "    return ea\n",
    "\n",
    "def extract_values(events):\n",
    "    steps = [e.step for e in events]\n",
    "    values = [e.value for e in events]\n",
    "    return steps, values\n",
    "\n",
    "# Paths to your logs\n",
    "train_log = \"/home/angel/Documents/MNIST-fashion-classification/notebooks/my_logs/run_2025_06_18_09_49_17/train\"\n",
    "val_log   = \"/home/angel/Documents/MNIST-fashion-classification/notebooks/my_logs/run_2025_06_18_09_49_17/validation\"\n",
    "\n",
    "# Load event accumulators\n",
    "train_ea = load_event_tags(train_log)\n",
    "val_ea   = load_event_tags(val_log)\n",
    "\n",
    "# Show tags from TensorBoard\n",
    "print(\"ğŸ“¦ Train log tags:\")\n",
    "for k, v in train_ea.Tags().items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "print(\"\\nğŸ“¦ Validation log tags:\")\n",
    "for k, v in val_ea.Tags().items():\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "# Check for scalar tags\n",
    "train_scalar_tags = train_ea.Tags().get('scalars', [])\n",
    "val_scalar_tags = val_ea.Tags().get('scalars', [])\n",
    "\n",
    "common_tags = list(set(train_scalar_tags) & set(val_scalar_tags))\n",
    "\n",
    "if not common_tags:\n",
    "    print(\"\\nâŒ No scalar tags found in both logs to plot.\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Common scalar tags found: {common_tags}\")\n",
    "\n",
    "    # Plotting\n",
    "    fig, axes = plt.subplots(1, len(common_tags), figsize=(6 * len(common_tags), 5))\n",
    "\n",
    "    # Ensure axes is always iterable\n",
    "    if len(common_tags) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, tag in enumerate(common_tags):\n",
    "        train_events = train_ea.Scalars(tag)\n",
    "        val_events = val_ea.Scalars(tag)\n",
    "\n",
    "        train_steps, train_values = extract_values(train_events)\n",
    "        val_steps, val_values = extract_values(val_events)\n",
    "\n",
    "        axes[i].plot(train_steps, train_values, label=f\"Train {tag}\")\n",
    "        axes[i].plot(val_steps, val_values, label=f\"Val {tag}\")\n",
    "        axes[i].set_title(tag)\n",
    "        axes[i].set_xlabel(\"Step\")\n",
    "        axes[i].set_ylabel(tag)\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c18f834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Model Comparison Table:\n",
      "\n",
      "                         Model Train Loss Train Accuracy Val Loss  \\\n",
      "0                     Baseline       None           None     None   \n",
      "1                    BatchNorm       None           None     None   \n",
      "2          Dropout + BatchNorm       None           None     None   \n",
      "3  Dropout + BN + LR Scheduler       None           None     None   \n",
      "\n",
      "  Val Accuracy Final LR  \n",
      "0         None     None  \n",
      "1         None     None  \n",
      "2         None     None  \n",
      "3         None     None  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from tensorflow.python.framework import tensor_util\n",
    "\n",
    "# Paths to log directories\n",
    "train_dir = \"/home/angel/Documents/MNIST-fashion-classification/notebooks/my_logs/run_2025_06_18_09_49_17/train\"\n",
    "val_dir   = \"/home/angel/Documents/MNIST-fashion-classification/notebooks/my_logs/run_2025_06_18_09_49_17/validation\"\n",
    "\n",
    "# Define model labels manually in the order they were trained\n",
    "model_names = [\n",
    "    \"Baseline\",\n",
    "    \"BatchNorm\",\n",
    "    \"Dropout + BatchNorm\",\n",
    "    \"Dropout + BN + LR Scheduler\"\n",
    "]\n",
    "\n",
    "def get_last_tensor_value(events):\n",
    "    if not events:\n",
    "        return None\n",
    "    tensor_proto = events[-1].tensor_proto\n",
    "    return float(tensor_util.make_ndarray(tensor_proto).squeeze())\n",
    "\n",
    "def extract_metrics_from_file(path, is_train=True):\n",
    "    ea = EventAccumulator(path)\n",
    "    ea.Reload()\n",
    "    tags = ea.Tags().get(\"tensors\", [])\n",
    "\n",
    "    def get(tag):\n",
    "        try:\n",
    "            if tag in tags:\n",
    "                return get_last_tensor_value(ea.Tensors(tag))\n",
    "            return None\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    if is_train:\n",
    "        return {\n",
    "            \"Train Loss\": get(\"epoch_loss\"),\n",
    "            \"Train Accuracy\": get(\"epoch_accuracy\"),\n",
    "            \"Final LR\": get(\"epoch_learning_rate\")\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"Val Loss\": get(\"evaluation_loss_vs_iterations\"),\n",
    "            \"Val Accuracy\": get(\"evaluation_accuracy_vs_iterations\")\n",
    "        }\n",
    "\n",
    "# Get all event files\n",
    "train_files = sorted([\n",
    "    os.path.join(train_dir, f)\n",
    "    for f in os.listdir(train_dir)\n",
    "    if f.startswith(\"events.out\")\n",
    "])\n",
    "\n",
    "val_files = sorted([\n",
    "    os.path.join(val_dir, f)\n",
    "    for f in os.listdir(val_dir)\n",
    "    if f.startswith(\"events.out\")\n",
    "])\n",
    "\n",
    "# Combine metrics\n",
    "data = []\n",
    "for i in range(min(len(train_files), len(val_files))):\n",
    "    row = {\"Model\": model_names[i] if i < len(model_names) else f\"Model {i+1}\"}\n",
    "    row.update(extract_metrics_from_file(train_files[i], is_train=True))\n",
    "    row.update(extract_metrics_from_file(val_files[i], is_train=False))\n",
    "    data.append(row)\n",
    "\n",
    "# Create table\n",
    "df = pd.DataFrame(data)\n",
    "df = df[[\"Model\", \"Train Loss\", \"Train Accuracy\", \"Val Loss\", \"Val Accuracy\", \"Final LR\"]]\n",
    "\n",
    "print(\"\\nğŸ“Š Model Comparison Table:\\n\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a667880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Model Comparison Table:\n",
      "\n",
      "                         Model  Train Loss  Train Accuracy  Val Loss  \\\n",
      "0                     Baseline      0.2280          0.9237    1.3741   \n",
      "1                    BatchNorm      0.0179          0.9943    0.8862   \n",
      "2          Dropout + BatchNorm      0.0576          0.9801    0.5158   \n",
      "3  Dropout + BN + LR Scheduler      0.0303          0.9892    0.5414   \n",
      "\n",
      "   Val Accuracy  \n",
      "0        0.8652  \n",
      "1        0.8894  \n",
      "2        0.8992  \n",
      "3        0.9052  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "# Rutas a los logs\n",
    "train_dir = \"/home/angel/Documents/MNIST-fashion-classification/notebooks/my_logs/run_2025_06_18_09_49_17/train\"\n",
    "val_dir = \"/home/angel/Documents/MNIST-fashion-classification/notebooks/my_logs/run_2025_06_18_09_49_17/validation\"\n",
    "\n",
    "# Nombres de modelos en orden\n",
    "model_names = [\n",
    "    \"Baseline\",\n",
    "    \"BatchNorm\",\n",
    "    \"Dropout + BatchNorm\",\n",
    "    \"Dropout + BN + LR Scheduler\"\n",
    "]\n",
    "\n",
    "# Leer el Ãºltimo valor de un tensor\n",
    "def get_last_tensor_value(events):\n",
    "    if not events:\n",
    "        return None\n",
    "    return float(tf.make_ndarray(events[-1].tensor_proto).squeeze())\n",
    "\n",
    "# Extraer mÃ©tricas de un archivo\n",
    "def extract_metrics(file_path, keys):\n",
    "    ea = EventAccumulator(file_path)\n",
    "    ea.Reload()\n",
    "    tensors = ea.Tags().get(\"tensors\", [])\n",
    "    values = {}\n",
    "    for key in keys:\n",
    "        if key in tensors:\n",
    "            events = ea.Tensors(key)\n",
    "            values[key] = get_last_tensor_value(events)\n",
    "        else:\n",
    "            values[key] = None\n",
    "    return values\n",
    "\n",
    "# Obtener archivos\n",
    "train_files = sorted([\n",
    "    os.path.join(train_dir, f) for f in os.listdir(train_dir)\n",
    "    if f.startswith(\"events.out\")\n",
    "])\n",
    "\n",
    "val_files = sorted([\n",
    "    os.path.join(val_dir, f) for f in os.listdir(val_dir)\n",
    "    if f.startswith(\"events.out\")\n",
    "])\n",
    "\n",
    "# Armar tabla\n",
    "data = []\n",
    "for i in range(min(len(train_files), len(val_files))):\n",
    "    row = {\"Model\": model_names[i] if i < len(model_names) else f\"Model {i+1}\"}\n",
    "    train_metrics = extract_metrics(train_files[i], [\"epoch_loss\", \"epoch_accuracy\"])\n",
    "    val_metrics = extract_metrics(val_files[i], [\"epoch_loss\", \"epoch_accuracy\"])\n",
    "\n",
    "    row[\"Train Loss\"] = round(train_metrics[\"epoch_loss\"], 4) if train_metrics[\"epoch_loss\"] is not None else None\n",
    "    row[\"Train Accuracy\"] = round(train_metrics[\"epoch_accuracy\"], 4) if train_metrics[\"epoch_accuracy\"] is not None else None\n",
    "    row[\"Val Loss\"] = round(val_metrics[\"epoch_loss\"], 4) if val_metrics[\"epoch_loss\"] is not None else None\n",
    "    row[\"Val Accuracy\"] = round(val_metrics[\"epoch_accuracy\"], 4) if val_metrics[\"epoch_accuracy\"] is not None else None\n",
    "\n",
    "    data.append(row)\n",
    "\n",
    "# Mostrar tabla\n",
    "df = pd.DataFrame(data)\n",
    "print(\"\\nğŸ“Š Model Comparison Table:\\n\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
